training ur own diffusion model is...hard
https://github.com/huggingface/diffusers/tree/main/examples/unconditional_image_generation

but training scripts make it easier?
https://huggingface.co/docs/diffusers/training/overview

you'll need to make a dataset that like this
https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions
using this:
https://github.com/salesforce/LAVIS
for blip captioning

OR USE HUGGINGFACE
however to do this u had to install trasnformwrs from source pip install git+https://github.com/huggingface/transformers

So how do we find logits_per_image?
first logit_scale_init_value=2.6592 https://github.com/huggingface/transformers/blob/main/src/transformers/models/blip/configuration_blip.py#L297C66-L297C72
self.logit_scale = nn.Parameter(torch.tensor(self.config.logit_scale_init_value)) https://github.com/huggingface/transformers/blob/main/src/transformers/models/blip/modeling_blip.py#L746C9-L746C90


logit_scale = self.logit_scale.exp()
logits_per_text = torch.matmul(text_embeds, image_embeds.t()) * logit_scale
logits_per_image = logits_per_text.t()
'''
https://github.com/huggingface/transformers/blob/main/src/transformers/models/blip/modeling_blip.py#L896C9-L899C47
not sure where about text_embeds and image_embeds tbh
'''


heres how to train diffusion manually:
https://huggingface.co/docs/diffusers/tutorials/basic_training

heres a script for DDPO:
https://github.com/huggingface/trl/blob/main/examples/scripts/ddpo.py

For the DDPO scheduler, you can't set cache_dir normally?